# Equation Learner (EQL) with Lâ‚€ Regularization

## Overview

This repository implements a symbolic regression model based on the **Equation Learner (EQL)** framework. The goal is to train neural networks that **output interpretable mathematical expressions**, bridging data-driven models with symbolic reasoning.

This work:

* Is **inspired by the MIT paper** by Kim et al. (2019) \[[arXiv:1912.04825](https://arxiv.org/abs/1912.04825)]
* Explores **Lâ‚€ regularization** to promote sparsity (following Louizos et al., 2017)
* Serves as a **prerequisite to future NOMTO-style developments**, focusing purely on symbolic expression recovery (not Neural Operators)

>  This project **does not implement NOMTO**, but includes a comparative study and roadmap in the attached theory documents.

---

## Repository Contents

```
.
â”œâ”€â”€ EQLs_EPFL_Training0.ipynb                    # Main implementation (PyTorch)
â”œâ”€â”€ EQL Model Mind Map.png                       # Graphical overview of model components
â”œâ”€â”€ Theory - Focus on L0 Regularization.pdf       # Notes on sparsity and regularization
â”œâ”€â”€ Theory - Symbolic Regression and NOMTO.pdf    # Notes on Neural Operators (not implemented)
â”œâ”€â”€ Presentation - From Symbolic Regression to Neural Operators.pdf
â”œâ”€â”€ Paper - Kim et al., Equation Learner (MIT).pdf
```

---

## Features

* âœ… Symbolic regression with trainable neural network
* âœ… Interpretable basis functions: `sin`, `log`, `sign`, `square`, `identity`, `product`
* âœ… Lâ‚€ regularization using the hard-concrete distribution
* âœ… Final symbolic equation extraction using SymPy
* âœ… Multi-run benchmarks with stability analysis

---

## Example: Fitting sin(x)

```python
bench = Benchmark(
    n_layers=2,
    reg_weight=5e-6,
    learning_rate=1e-2,
    n_epochs1=2001,
    n_epochs2=2001
)
bench.benchmark(lambda x: np.sin(x), func_name="sin(x)", trials=5)
```

Resulting expression (example):

```latex
y(x) = 0.05x + 0.92\sin(1.04x)
```

---

## Mind Map

To aid understanding, a complete [**mind map**](./EQL%20Model%20Mind%20Map.png) is included, covering:

* Symbolic function definitions
* EQL architecture (with/without Lâ‚€)
* Symbolic expression extraction
* Testing loop and benchmarks

---

## Inspirations and Comparisons

| Concept                   | Implemented? | Source                                                   |
| ------------------------- | ------------ | -------------------------------------------------------- |
| Symbolic Regression (EQL) | âœ…            | [Kim et al., 2019](https://arxiv.org/abs/1912.04825)     |
| Lâ‚€ Regularization         | âœ…            | [Louizos et al., 2017](https://arxiv.org/abs/1712.01312) |
| NOMTO Operator Extraction | âŒ            | [Garmaev et al., 2024](https://arxiv.org/abs/2501.08086) |

---

## Requirements

* Python 3.8+
* PyTorch
* NumPy
* SymPy
* matplotlib
* tqdm

Optional: Run in Google Colab for easy GPU access.

---

## Limitations

* âŒ No PDE rediscovery
* âŒ No function-to-function learning (Neural Operators)
* âŒ No NOMTO symbolic tree parser
* âŒ Limited to 1D/2D symbolic functions (future upgrade planned)

---

## Next Steps

Planned upgrades:

* âœ… Switch between Lâ‚ and Lâ‚€/HardConcrete regularization
* ğŸ”„ Integrate Neural Operators (FNO/CNO)
* ğŸ”„ Benchmark against KANs and NOMTO
* ğŸ”„ Automatic symbolic tree extraction

---

## References

* Samuel Kim et al., [*Equation Learner for Symbolic Regression*](https://arxiv.org/abs/1912.04825)
* Christos Louizos et al., [*Lâ‚€ Regularization*](https://arxiv.org/abs/1712.01312)
* Sergei Garmaev et al., [*NOMTO*](https://arxiv.org/abs/2501.08086)

---

## Author

**Yasser El Kouhen**
* AI Research Intern @ EPFL IMOS Lab
* GitHub: [@Yasser-EL-KOUHEN](https://github.com/Yasser-EL-KOUHEN)
* Contact: [yasserelkouhen5@gmail.com](mailto:yasserelkouhen5@gmail.com)

